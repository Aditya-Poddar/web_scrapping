{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5e106b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pdfkit\n",
      "  Downloading pdfkit-1.0.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: pdfkit\n",
      "Successfully installed pdfkit-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pdfkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b88766ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting reportlab\n",
      "  Downloading reportlab-4.0.4-py3-none-any.whl (1.9 MB)\n",
      "     ---------------------------------------- 1.9/1.9 MB 2.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from reportlab) (9.2.0)\n",
      "Installing collected packages: reportlab\n",
      "Successfully installed reportlab-4.0.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install reportlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4437071d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "     -------------------------------------- 232.6/232.6 kB 1.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from PyPDF2) (4.3.0)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c3028e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\adityakumar\\appdata\\roaming\\python\\python39\\site-packages (3.0.1)\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from PyPDF2) (4.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f316fe8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Links extracted and saved to: links.txt\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_links_from_table(url, table_class, output_file):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    table = soup.find('table', class_=table_class)\n",
    "    \n",
    "    links = []\n",
    "    if table:\n",
    "        rows = table.find_all('tr')\n",
    "        for row in rows:\n",
    "            cells = row.find_all('td')\n",
    "            for cell in cells:\n",
    "                link = cell.find('a')\n",
    "                if link:\n",
    "                    link_href = link['href']\n",
    "                    links.append(link_href)\n",
    "    \n",
    "    with open(output_file, 'w') as file:\n",
    "        for link in links:\n",
    "            file.write('https://www.indiacode.nic.in'+link + '\\n')\n",
    "    \n",
    "    print(f\"Links extracted and saved to: {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "url = \"https://www.indiacode.nic.in/handle/123456789/1362/simple-search?page-token=8e9bfc6a3c17&page-token-value=ccd4835353ce4a659cc2c83adc61fbce&nccharset=EB8ACF46&location=123456789%2F1359&query=act&rpp=100&sort_by=score&order=desc\"  # Replace with the URL of the website\n",
    "table_class = \"table table-hover\"  # Replace with the class name of the table\n",
    "output_file = \"links.txt\"  # Replace with the desired output file path\n",
    "\n",
    "extract_links_from_table(url, table_class, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fc157ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF extracted and saved to: extracted_pdf.pdf\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_pdf_from_link(link, output_file):\n",
    "    response = requests.get(link)\n",
    "    \n",
    "    # Check if the response is successful\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        standard_span = soup.find('span', class_='standard')\n",
    "        \n",
    "        # Check if the <span> element with class \"standard\" exists\n",
    "        if standard_span:\n",
    "            pdf_link = \"https://www.indiacode.nic.in/\" + standard_span.find('a')['href']\n",
    "            pdf_response = requests.get(pdf_link)\n",
    "            \n",
    "            # Check if the response content type is PDF\n",
    "            if pdf_response.headers.get('content-type') == 'application/pdf':\n",
    "                with open(output_file, 'wb') as file:\n",
    "                    file.write(pdf_response.content)\n",
    "                print(f\"PDF extracted and saved to: {output_file}\")\n",
    "            else:\n",
    "                print(\"The linked file is not a PDF.\")\n",
    "        else:\n",
    "            print(\"No <span> element with class 'standard' found.\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve the link.\")\n",
    "\n",
    "# Example usage\n",
    "link = \"https://www.indiacode.nic.in/handle/123456789/19033?view_type=search&sam_handle=123456789/1362\"  # Replace with the specific link to follow\n",
    "output_file = \"extracted_pdf.pdf\"  # Replace with the desired output file path\n",
    "\n",
    "extract_pdf_from_link(link, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef421ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF extracted and saved to: C:\\Users\\AdityaKumar\\Downloads3.pdf\n",
      "PDF extracted and saved to: C:\\Users\\AdityaKumar\\Downloads51.pdf\n",
      "PDF extracted and saved to: C:\\Users\\AdityaKumar\\Downloads52.pdf\n",
      "PDF extracted and saved to: C:\\Users\\AdityaKumar\\Downloads53.pdf\n",
      "PDF extracted and saved to: C:\\Users\\AdityaKumar\\Downloads55.pdf\n",
      "PDF extracted and saved to: C:\\Users\\AdityaKumar\\Downloads56.pdf\n",
      "PDF extracted and saved to: C:\\Users\\AdityaKumar\\Downloads57.pdf\n",
      "PDF extracted and saved to: C:\\Users\\AdityaKumar\\Downloads61.pdf\n",
      "PDF extracted and saved to: C:\\Users\\AdityaKumar\\Downloads66.pdf\n",
      "PDF extracted and saved to: C:\\Users\\AdityaKumar\\Downloads91.pdf\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def extract_pdf_from_link(link, output_file):\n",
    "    response = requests.get(link)\n",
    "    \n",
    "    # Check if the response is successful\n",
    "    if response.status_code == 200:\n",
    "        # Check if the response content type is PDF\n",
    "        if response.headers.get('content-type') == 'application/pdf':\n",
    "            with open(output_file, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "            \n",
    "            # Check if the PDF has at least 30 pages\n",
    "            pdf_reader = PdfReader(output_file)\n",
    "            num_pages = len(pdf_reader.pages)\n",
    "            \n",
    "            if num_pages >= 30:\n",
    "                print(f\"PDF extracted and saved to: {output_file}\")\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            print(\"The linked file is not a PDF.\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve the link.\")\n",
    "\n",
    "# Example usage\n",
    "links_file = \"links.txt\"  # Replace with the path to the file containing the links\n",
    "output_folder = \"C:\\\\Users\\\\AdityaKumar\\\\Downloads\"  # Replace with the desired output folder path\n",
    "\n",
    "with open(links_file, 'r') as file:\n",
    "    links = file.readlines()\n",
    "\n",
    "if links:\n",
    "    for i, link in enumerate(links):\n",
    "        link = link.strip()\n",
    "        response = requests.get(link)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        span = soup.find('span', class_='standard')\n",
    "        if span:\n",
    "            span_link = span.find('a')\n",
    "            if span_link:\n",
    "                span_link_href = \"https://www.indiacode.nic.in/\" + span_link['href']\n",
    "                output_file = f\"{output_folder}{i}.pdf\"\n",
    "                extract_pdf_from_link(span_link_href, output_file)\n",
    "                \n",
    "else:\n",
    "    print(\"No links found in the file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2433d0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF downloaded and saved to: pdf_hry_short_titles_amendment_act%2c_2021_-_cs.pdf\n",
      "PDF downloaded and saved to: pdf_act_no.1_of_2019_.pdf\n",
      "PDF downloaded and saved to: pdf_a1925-35.pdf\n",
      "PDF downloaded and saved to: pdf_self_supporting_act.pdf\n",
      "PDF downloaded and saved to: pdf_the_abu_area_laws_act%2c_1975.pdf\n",
      "PDF downloaded and saved to: pdf_act_no.1_of_2022.pdf\n",
      "PDF downloaded and saved to: pdf_repealing_%28second%29_act%2c_2016_%2815_of_2017%29.pdf\n",
      "PDF downloaded and saved to: pdf_the_maharashtra_%28change_of_short_titles_of_certain_bombay_acts%29_act%2c_2011.pdf\n",
      "PDF downloaded and saved to: pdf_AA1894___09.pdf\n",
      "PDF downloaded and saved to: pdf_A1967-13.pdf\n",
      "PDF downloaded and saved to: pdf_the_rajasthan_laws_repealing_act%2c_1997.pdf\n",
      "PDF downloaded and saved to: pdf_%2824_of_2012%29the_maharashtra_%28change_of_short_titles_of_certain_bombay_acts%29_act%2c_2011..pdf\n",
      "PDF downloaded and saved to: pdf_a2016____23.pdf\n",
      "PDF downloaded and saved to: pdf_raj._prohibition_act_1981.pdf\n",
      "PDF downloaded and saved to: pdf_the_special_marriage_act_1954_extension_to_nagaland_act_2002.pdf\n",
      "PDF downloaded and saved to: pdf_act_no._1_of_2018.pdf\n",
      "PDF downloaded and saved to: pdf_act_no.5_of_2019.pdf\n",
      "PDF downloaded and saved to: pdf_image_025.pdf\n",
      "PDF downloaded and saved to: pdf_A2018-02.pdf\n",
      "PDF downloaded and saved to: pdf_the_assam_college_education_%28provincialisation%29_act%2c_repealing_act%2c_1998._0.pdf\n",
      "PDF downloaded and saved to: pdf_act_no_vii_of_1961.pdf\n",
      "PDF downloaded and saved to: pdf_the_meghalaya_legislative_assembly_%28fixation_of_quorum%29_act%2c_act_no.7_of_1989.pdf\n",
      "PDF downloaded and saved to: pdf_lokayukta-act-english.pdf\n",
      "PDF downloaded and saved to: pdf_189108.pdf\n",
      "PDF downloaded and saved to: pdf_Athe_meghalaya_benami.pdf\n",
      "PDF downloaded and saved to: pdf_act_no._14.pdf\n",
      "PDF downloaded and saved to: pdf_he_meghalaya_state.pdf\n",
      "PDF downloaded and saved to: pdf_registration_%28amendment_and_validation_of_transfer_of_property%29_act%2c_1955.pdf\n",
      "PDF downloaded and saved to: pdf_ACT%20No.11%20of%202018.pdf\n",
      "PDF downloaded and saved to: pdf_ACT%20NO%2008-2016.pdf\n",
      "PDF downloaded and saved to: pdf_ACT%20No.12%20of%202018.pdf\n",
      "PDF downloaded and saved to: pdf_ACT%20NO%2002-2015.pdf\n",
      "PDF downloaded and saved to: pdf_ACT%20NO%2003-2015.pdf\n",
      "PDF downloaded and saved to: pdf_ACT%20NO%2016-2015.pdf\n",
      "PDF downloaded and saved to: pdf_1542092200950_ACT%20NO%2002-2015.pdf\n",
      "PDF downloaded and saved to: pdf_AP%20Excise%20ACt.pdf\n",
      "PDF downloaded and saved to: pdf_ACT%20NO%2008-2015.pdf\n",
      "PDF downloaded and saved to: pdf_the_rajasthan_state_cattle_fairs_act%2c_1963.pdf\n",
      "PDF downloaded and saved to: pdf_repealingact2004.pdf\n",
      "PDF downloaded and saved to: pdf_A1974-54.pdf\n",
      "PDF downloaded and saved to: pdf_a2019____31.pdf\n",
      "PDF downloaded and saved to: pdf_pb_state_commission_sc_act_2004_amendment_act_2006.pdf\n",
      "PDF downloaded and saved to: pdf_ACT%20NO%2010-2016.pdf\n",
      "PDF downloaded and saved to: pdf_ACT%20NO%2010-2016.pdf\n",
      "PDF downloaded and saved to: pdf_a192524.pdf\n",
      "PDF downloaded and saved to: pdf_36of2011%28E%29.pdf\n",
      "PDF downloaded and saved to: pdf_act_7_of_2017.pdf\n",
      "PDF downloaded and saved to: pdf_52_of_2020_%28e%29.pdf\n",
      "PDF downloaded and saved to: pdf_a1899-2 .pdf\n",
      "PDF downloaded and saved to: pdf_a1899-2 .pdf\n",
      "PDF downloaded and saved to: pdf_a1899-2 .pdf\n",
      "PDF downloaded and saved to: pdf_A1869-04.pdf\n",
      "PDF downloaded and saved to: pdf_A1988-59.pdf\n",
      "PDF downloaded and saved to: pdf_a1899-2 .pdf\n",
      "PDF downloaded and saved to: pdf_a1899-2 .pdf\n",
      "PDF downloaded and saved to: pdf_A1948____08.pdf\n",
      "PDF downloaded and saved to: pdf_A1890-1.pdf\n",
      "PDF downloaded and saved to: pdf_AApolice1861___05.pdf\n",
      "PDF downloaded and saved to: pdf_A1948-63.pdf\n",
      "PDF downloaded and saved to: pdf_16_of_2004_%28e%29.pdf\n",
      "PDF downloaded and saved to: pdf_a1962-42.pdf\n",
      "PDF downloaded and saved to: pdf_act_2_of_1962.pdf\n",
      "PDF downloaded and saved to: pdf_a2015___17.pdf\n",
      "PDF downloaded and saved to: pdf_A1882-04.pdf\n",
      "PDF downloaded and saved to: pdf_the_rajasthan_laws_repealing_act%2c_2015.pdf\n",
      "PDF downloaded and saved to: pdf_189710.pdf\n",
      "PDF downloaded and saved to: pdf_189710.pdf\n",
      "PDF downloaded and saved to: pdf_189710.pdf\n",
      "PDF downloaded and saved to: pdf_189710.pdf\n",
      "PDF downloaded and saved to: pdf_A1915-10.pdf\n",
      "PDF downloaded and saved to: pdf_a2021-40.pdf\n",
      "PDF downloaded and saved to: pdf_pb_state_commission_act_2004_amendment_act_2019.pdf\n",
      "PDF downloaded and saved to: pdf_lambardari_act%2c_1972.pdf\n",
      "PDF downloaded and saved to: pdf_1551073129124_lambardari_act%2c_1972.pdf\n",
      "PDF downloaded and saved to: pdf_the_haryana_settlement_of_outstanding_dues_act%2c_2017%2835_of_2017%29-ulb.pdf\n",
      "PDF downloaded and saved to: pdf_punjab_school_education_board_%28amendment%29_act%2c_2018.pdf\n",
      "PDF downloaded and saved to: pdf_A2018-04.pdf\n",
      "PDF downloaded and saved to: pdf_5._the_kerala_essential_articles_control_%28temporary_powers%29_continuance_act%2c_1979.pdf\n",
      "PDF downloaded and saved to: pdf_TRIPURA%20GENERAL%20CLAUSES%20ACT%2c%201966.pdf\n",
      "PDF downloaded and saved to: pdf_urban_immovable_property_tax_%28repeal_and_saving%29_act%2c_2002.pdf\n",
      "PDF downloaded and saved to: pdf_raj._appropriation_acts_%28repeal%29_act%2c_2017.pdf\n",
      "PDF downloaded and saved to: pdf_a2015----19.pdf\n",
      "PDF downloaded and saved to: pdf_the_meghalaya_municipal_%28garo_hills_autonomous_district%29_act%2c1978%28act_7_of_1978%29.pdf\n",
      "PDF downloaded and saved to: pdf_act_27_of_1956.pdf\n",
      "PDF downloaded and saved to: pdf_1556191273430_ex-417.pdf\n",
      "PDF downloaded and saved to: pdf_1556191424861_ex-416.pdf\n",
      "PDF downloaded and saved to: pdf_23._the_kerala_finance_act_1989_sw.pdf\n",
      "PDF downloaded and saved to: pdf_rti_repeal_act%2c_2006.pdf\n",
      "PDF downloaded and saved to: pdf_extra_ordinary_no._09.pdf\n",
      "PDF downloaded and saved to: pdf_189710.pdf\n",
      "PDF downloaded and saved to: pdf_9%20of%202017.pdf\n",
      "PDF downloaded and saved to: pdf_punjabfisheriesact1914_%281%29.pdf\n",
      "PDF downloaded and saved to: pdf_06%20of%202017.pdf\n",
      "PDF downloaded and saved to: pdf_19%20of%202017.pdf\n",
      "PDF downloaded and saved to: pdf_a1908-13.pdf\n",
      "PDF downloaded and saved to: pdf_a1999-15.pdf\n",
      "PDF downloaded and saved to: pdf_a1992-12.pdf\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def download_pdf_from_link(link, output_file):\n",
    "    response = requests.get(link)\n",
    "    \n",
    "    # Check if the response is successful\n",
    "    if response.status_code == 200:\n",
    "        # Check if the response content type is PDF\n",
    "        if response.headers.get('content-type') == 'application/pdf':\n",
    "            # Check if the PDF has at least 30 pages\n",
    "            if len(response.content) >= 30:\n",
    "                with open(output_file, 'wb') as file:\n",
    "                    file.write(response.content)\n",
    "                print(f\"PDF downloaded and saved to: {output_file}\")\n",
    "            else:\n",
    "                print(\"The PDF does not have at least 30 pages.\")\n",
    "        else:\n",
    "            print(\"The linked file is not a PDF.\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve the link.\")\n",
    "\n",
    "# Example usage\n",
    "links_file = \"links.txt\"  # Replace with the path to the file containing the links\n",
    "\n",
    "with open(links_file, 'r') as file:\n",
    "    links = file.readlines()\n",
    "\n",
    "if links:\n",
    "    for link in links:\n",
    "        link = link.strip()\n",
    "        response = requests.get(link)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        spans = soup.find_all('span', class_='standard')\n",
    "        for span in spans:\n",
    "            span_link = span.find('a')\n",
    "            if span_link:\n",
    "                span_href = \"https://www.indiacode.nic.in/\" + span_link.get('href')\n",
    "                output_file = f\"pdf_{span_href.split('/')[-1]}\"\n",
    "                download_pdf_from_link(span_href, output_file)\n",
    "else:\n",
    "    print(\"No links found in the file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15652e77",
   "metadata": {},
   "outputs": [
    {
     "ename": "DeprecationError",
     "evalue": "PdfFileReader is deprecated and was removed in PyPDF2 3.0.0. Use PdfReader instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDeprecationError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18112\\2987013385.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mspan\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mspan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mpdf_link\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://www.indiacode.nic.in/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mspan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m             \u001b[0mdownload_pdf_from_link\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_link\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"output.pdf\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m             \u001b[1;32mbreak\u001b[0m  \u001b[1;31m# Stop after downloading the first PDF file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18112\\2987013385.py\u001b[0m in \u001b[0;36mdownload_pdf_from_link\u001b[1;34m(link, output_file)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'content-type'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'application/pdf'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[1;31m# Check if the PDF has at least 30 pages\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0mpdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPdfFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0mnum_pages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetNumPages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mnum_pages\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\PyPDF2\\_reader.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1972\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mPdfFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mPdfReader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pragma: no cover\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1973\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1974\u001b[1;33m         \u001b[0mdeprecation_with_replacement\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"PdfFileReader\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"PdfReader\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"3.0.0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1975\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m\"strict\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1976\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"strict\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m  \u001b[1;31m# maintain the default\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\PyPDF2\\_utils.py\u001b[0m in \u001b[0;36mdeprecation_with_replacement\u001b[1;34m(old_name, new_name, removed_in)\u001b[0m\n\u001b[0;32m    367\u001b[0m     \u001b[0mRaise\u001b[0m \u001b[0man\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mthat\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0mwas\u001b[0m \u001b[0malready\u001b[0m \u001b[0mremoved\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbut\u001b[0m \u001b[0mhas\u001b[0m \u001b[0ma\u001b[0m \u001b[0mreplacement\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m     \"\"\"\n\u001b[1;32m--> 369\u001b[1;33m     \u001b[0mdeprecation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDEPR_MSG_HAPPENED\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mold_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mremoved_in\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\PyPDF2\\_utils.py\u001b[0m in \u001b[0;36mdeprecation\u001b[1;34m(msg)\u001b[0m\n\u001b[0;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdeprecation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 351\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mDeprecationError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDeprecationError\u001b[0m: PdfFileReader is deprecated and was removed in PyPDF2 3.0.0. Use PdfReader instead."
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from PyPDF2 import PdfFileReader\n",
    "\n",
    "def download_pdf_from_link(link, output_file):\n",
    "    response = requests.get(link)\n",
    "    \n",
    "    # Check if the response is successful\n",
    "    if response.status_code == 200:\n",
    "        # Check if the response content type is PDF\n",
    "        if response.headers.get('content-type') == 'application/pdf':\n",
    "            # Check if the PDF has at least 30 pages\n",
    "            pdf = PdfFileReader(response.content)\n",
    "            num_pages = pdf.getNumPages()\n",
    "            if num_pages >= 30:\n",
    "                with open(output_file, 'wb') as file:\n",
    "                    file.write(response.content)\n",
    "                print(f\"PDF downloaded and saved to: {output_file}\")\n",
    "            else:\n",
    "                print(\"The PDF does not have at least 30 pages.\")\n",
    "        else:\n",
    "            print(\"The linked file is not a PDF.\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve the link.\")\n",
    "\n",
    "# Example usage\n",
    "links_file = \"links.txt\"  # Replace with the path to the file containing the links\n",
    "\n",
    "with open(links_file, 'r') as file:\n",
    "    links = file.readlines()\n",
    "\n",
    "if links:\n",
    "    for link in links:\n",
    "        link = link.strip()\n",
    "        \n",
    "        response = requests.get(link)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        span = soup.find('span', class_='standard')\n",
    "        if span and span.find('a'):\n",
    "            pdf_link = \"https://www.indiacode.nic.in/\" + span.find('a')['href']\n",
    "            download_pdf_from_link(pdf_link, \"output.pdf\")\n",
    "            break  # Stop after downloading the first PDF file\n",
    "else:\n",
    "    print(\"No links found in the file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce4685d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\hry_short_titles_amendment_act%2c_2021_-_cs.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\act_no.1_of_2019_.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\a1925-35.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\self_supporting_act.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\the_abu_area_laws_act%2c_1975.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\act_no.1_of_2022.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\repealing_%28second%29_act%2c_2016_%2815_of_2017%29.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\the_maharashtra_%28change_of_short_titles_of_certain_bombay_acts%29_act%2c_2011.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\AA1894___09.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\A1967-13.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\the_rajasthan_laws_repealing_act%2c_1997.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\%2824_of_2012%29the_maharashtra_%28change_of_short_titles_of_certain_bombay_acts%29_act%2c_2011..pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\a2016____23.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\raj._prohibition_act_1981.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\the_special_marriage_act_1954_extension_to_nagaland_act_2002.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\act_no._1_of_2018.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\act_no.5_of_2019.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\image_025.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\A2018-02.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\the_assam_college_education_%28provincialisation%29_act%2c_repealing_act%2c_1998._0.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\lokayukta-act-english.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\189108.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\Athe_meghalaya_benami.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\act_no._14.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\registration_%28amendment_and_validation_of_transfer_of_property%29_act%2c_1955.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\ACT%20No.11%20of%202018.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\ACT%20NO%2008-2016.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\ACT%20No.12%20of%202018.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\ACT%20NO%2002-2015.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\ACT%20NO%2003-2015.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\ACT%20NO%2016-2015.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\1542092200950_ACT%20NO%2002-2015.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\AP%20Excise%20ACt.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\ACT%20NO%2008-2015.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\the_rajasthan_state_cattle_fairs_act%2c_1963.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\A1974-54.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\a2019____31.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\pb_state_commission_sc_act_2004_amendment_act_2006.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\ACT%20NO%2010-2016.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\ACT%20NO%2010-2016.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\a192524.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\36of2011%28E%29.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\52_of_2020_%28e%29.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\a1899-2 .pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\a1899-2 .pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\a1899-2 .pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\A1869-04.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\A1988-59.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\a1899-2 .pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\a1899-2 .pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\A1948____08.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\A1890-1.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\AApolice1861___05.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\A1948-63.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\16_of_2004_%28e%29.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\a1962-42.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\act_2_of_1962.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\a2015___17.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\A1882-04.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\the_rajasthan_laws_repealing_act%2c_2015.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\189710.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\189710.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\189710.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\189710.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\A1915-10.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\a2021-40.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\pb_state_commission_act_2004_amendment_act_2019.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\1551073129124_lambardari_act%2c_1972.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\the_haryana_settlement_of_outstanding_dues_act%2c_2017%2835_of_2017%29-ulb.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\A2018-04.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\5._the_kerala_essential_articles_control_%28temporary_powers%29_continuance_act%2c_1979.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\TRIPURA%20GENERAL%20CLAUSES%20ACT%2c%201966.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\urban_immovable_property_tax_%28repeal_and_saving%29_act%2c_2002.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\raj._appropriation_acts_%28repeal%29_act%2c_2017.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\a2015----19.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\the_meghalaya_municipal_%28garo_hills_autonomous_district%29_act%2c1978%28act_7_of_1978%29.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\act_27_of_1956.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\23._the_kerala_finance_act_1989_sw.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\extra_ordinary_no._09.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\189710.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\9%20of%202017.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\punjabfisheriesact1914_%281%29.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\06%20of%202017.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\19%20of%202017.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\a1908-13.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\a1999-15.pdf\n",
      "PDF downloaded successfully and saved at: C:\\Users\\AdityaKumar\\Downloads\\a1992-12.pdf\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def download_pdf(url, folder_path):\n",
    "    response = requests.get(url)\n",
    "    file_name = url.split('/')[-1]\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    \n",
    "    with open(file_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "    \n",
    "    print(f\"PDF downloaded successfully and saved at: {file_path}\")\n",
    "\n",
    "def process_link(link, folder_path):\n",
    "    response = requests.get(link)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    span_elements = soup.find_all('span', class_='standard')\n",
    "    for span in span_elements:\n",
    "        link = span.find('a')\n",
    "        if link:\n",
    "            pdf_url = \"https://www.indiacode.nic.in/\" + link['href']\n",
    "            pdf_response = requests.get(pdf_url)\n",
    "            content_type = pdf_response.headers.get('content-type')\n",
    "            content_length = pdf_response.headers.get('content-length')\n",
    "\n",
    "            if content_type == 'application/pdf' and int(content_length) >= 30 * 1024:  # Minimum 30 pages (30 KB assuming 1 KB per page)\n",
    "                download_pdf(pdf_url, folder_path)\n",
    "\n",
    "# Example usage\n",
    "link_file = \"links.txt\"  # Replace with the path to the 'link.txt' file\n",
    "folder_path = \"C:\\\\Users\\\\AdityaKumar\\\\Downloads\"  # Replace with the desired folder path to store the downloaded PDFs\n",
    "\n",
    "with open(link_file, 'r') as file:\n",
    "    links = file.readlines()\n",
    "\n",
    "if links:\n",
    "    for link in links:\n",
    "        process_link(link.strip(), folder_path)\n",
    "else:\n",
    "    print(\"No links found in the file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20408461",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\AdityaKumar\\\\pdf\\\\hry_short_titles_amendment_act%2c_2021_-_cs.pdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18112\\3207254431.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[0moutput_folder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"C:\\\\Users\\\\AdityaKumar\\\\pdf\"\u001b[0m  \u001b[1;31m# Replace with the desired folder path to store the downloaded PDFs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m \u001b[0mcrawl_and_download_pdfs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinks_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18112\\3207254431.py\u001b[0m in \u001b[0;36mcrawl_and_download_pdfs\u001b[1;34m(links_file, output_folder)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[0mpdf_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpdf_link\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mcheck_pdf_page_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_file\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m                 \u001b[0mdownload_pdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_folder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18112\\3207254431.py\u001b[0m in \u001b[0;36mcheck_pdf_page_count\u001b[1;34m(pdf_file)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcheck_pdf_page_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpdf_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mpdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPdfFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mpage_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetNumPages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\AdityaKumar\\\\pdf\\\\hry_short_titles_amendment_act%2c_2021_-_cs.pdf'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from PyPDF2 import PdfFileReader\n",
    "\n",
    "def download_pdf(url, output_folder):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        file_name = url.split('/')[-1]\n",
    "        file_path = os.path.join(output_folder, file_name)\n",
    "        \n",
    "        with open(file_path, 'wb') as file:\n",
    "            file.write(response.content)\n",
    "        \n",
    "        print(f\"PDF downloaded and saved to: {file_path}\")\n",
    "    else:\n",
    "        print(f\"Failed to download PDF from: {url}\")\n",
    "\n",
    "def extract_links_from_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        links = file.readlines()\n",
    "    \n",
    "    return [link.strip() for link in links]\n",
    "\n",
    "def check_pdf_page_count(pdf_file):\n",
    "    with open(pdf_file, 'rb') as file:\n",
    "        pdf = PdfFileReader(file)\n",
    "        page_count = pdf.getNumPages()\n",
    "    \n",
    "    return page_count\n",
    "\n",
    "def crawl_and_download_pdfs(links_file, output_folder):\n",
    "    links = extract_links_from_file(links_file)\n",
    "    \n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    \n",
    "    for link in links:\n",
    "        response = requests.get(link)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        standard_spans = soup.find_all('span', class_='standard')\n",
    "        for span in standard_spans:\n",
    "            pdf_link = span.find('a')['href']\n",
    "            pdf_url = f\"{link}/{pdf_link}\"\n",
    "            \n",
    "            pdf_file = os.path.join(output_folder, pdf_link.split('/')[-1])\n",
    "            if check_pdf_page_count(pdf_file) >= 30:\n",
    "                download_pdf(pdf_url, output_folder)\n",
    "\n",
    "# Example usage\n",
    "links_file = \"links.txt\"  # Replace with the path to the file containing the links\n",
    "output_folder = \"C:\\\\Users\\\\AdityaKumar\\\\pdf\"  # Replace with the desired folder path to store the downloaded PDFs\n",
    "\n",
    "crawl_and_download_pdfs(links_file, output_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ba5c2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "from PyPDF2 import PdfFileReader\n",
    "\n",
    "def download_pdf(url, folder_path):\n",
    "    response = requests.get(url)\n",
    "    # Ensure that the response is a PDF file\n",
    "    if response.headers.get('content-type') == 'application/pdf':\n",
    "        # Check the number of pages in the PDF\n",
    "        pdf_content = response.content\n",
    "        num_pages = get_num_pdf_pages(pdf_content)\n",
    "        if num_pages >= 30:\n",
    "            # Extract the file name from the URL\n",
    "            file_name = url.split('/')[-1]\n",
    "            # Create the folder if it doesn't exist\n",
    "            if not os.path.exists(folder_path):\n",
    "                os.makedirs(folder_path)\n",
    "            # Save the PDF file\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            with open(file_path, 'wb') as file:\n",
    "                file.write(pdf_content)\n",
    "            print(f\"PDF downloaded successfully and saved at: {file_path}\")\n",
    "        else:\n",
    "            print(f\"The PDF has fewer than 30 pages and will not be downloaded.\")\n",
    "    else:\n",
    "        print(f\"The provided URL does not lead to a PDF file.\")\n",
    "\n",
    "def get_num_pdf_pages(pdf_content):\n",
    "    # Use PyPDF2 library to get the number of pages in the PDF\n",
    "    pdf = PdfFileReader(io.BytesIO(pdf_content))\n",
    "    num_pages = pdf.getNumPages()\n",
    "    return num_pages\n",
    "\n",
    "def process_links_from_file(links_file, folder_path):\n",
    "    with open(links_file, 'r') as file:\n",
    "        links = file.readlines()\n",
    "\n",
    "    for link in links:\n",
    "        link =\"https://www.indiacode.nic.in/\" +  link.strip()\n",
    "        response = requests.get(link)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        span_elements = soup.find_all('span', class_='standard')\n",
    "        for span in span_elements:\n",
    "            link_element = span.find('a')\n",
    "            if link_element:\n",
    "                pdf_url = link_element.get('href')\n",
    "                download_pdf(pdf_url, folder_path)\n",
    "\n",
    "# Example usage\n",
    "links_file = \"links.txt\"  # Replace with the path to the file containing the links\n",
    "folder_path = \"C:\\\\Users\\\\AdityaKumar\\\\pdf\"  # Replace with the desired folder path\n",
    "\n",
    "process_links_from_file(links_file, folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea89c22d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
