{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5e106b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting pdfkit\n",
      "  Downloading pdfkit-1.0.0-py3-none-any.whl (12 kB)\n",
      "Installing collected packages: pdfkit\n",
      "Successfully installed pdfkit-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pdfkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b88766ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting reportlab\n",
      "  Downloading reportlab-4.0.4-py3-none-any.whl (1.9 MB)\n",
      "     ---------------------------------------- 1.9/1.9 MB 2.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pillow>=9.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from reportlab) (9.2.0)\n",
      "Installing collected packages: reportlab\n",
      "Successfully installed reportlab-4.0.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install reportlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4437071d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "     -------------------------------------- 232.6/232.6 kB 1.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from PyPDF2) (4.3.0)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c3028e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: PyPDF2 in c:\\users\\adityakumar\\appdata\\roaming\\python\\python39\\site-packages (3.0.1)\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from PyPDF2) (4.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f316fe8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Links extracted and saved to: links.txt\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_links_from_table(url, table_class, output_file):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    table = soup.find('table', class_=table_class)\n",
    "    \n",
    "    links = []\n",
    "    if table:\n",
    "        rows = table.find_all('tr')\n",
    "        for row in rows:\n",
    "            cells = row.find_all('td')\n",
    "            for cell in cells:\n",
    "                link = cell.find('a')\n",
    "                if link:\n",
    "                    link_href = link['href']\n",
    "                    links.append(link_href)\n",
    "    \n",
    "    with open(output_file, 'w') as file:\n",
    "        for link in links:\n",
    "            file.write('https://www.indiacode.nic.in'+link + '\\n')\n",
    "    \n",
    "    print(f\"Links extracted and saved to: {output_file}\")\n",
    "\n",
    "# Example usage\n",
    "url = \"https://www.indiacode.nic.in/handle/123456789/1362/simple-search?page-token=8e9bfc6a3c17&page-token-value=ccd4835353ce4a659cc2c83adc61fbce&nccharset=EB8ACF46&location=123456789%2F1359&query=act&rpp=100&sort_by=score&order=desc\"  # Replace with the URL of the website\n",
    "table_class = \"table table-hover\"  # Replace with the class name of the table\n",
    "output_file = \"links.txt\"  # Replace with the desired output file path\n",
    "\n",
    "extract_links_from_table(url, table_class, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fc157ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF extracted and saved to: extracted_pdf.pdf\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_pdf_from_link(link, output_file):\n",
    "    response = requests.get(link)\n",
    "    \n",
    "    # Check if the response is successful\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        standard_span = soup.find('span', class_='standard')\n",
    "        \n",
    "        # Check if the <span> element with class \"standard\" exists\n",
    "        if standard_span:\n",
    "            pdf_link = \"https://www.indiacode.nic.in/\" + standard_span.find('a')['href']\n",
    "            pdf_response = requests.get(pdf_link)\n",
    "            \n",
    "            # Check if the response content type is PDF\n",
    "            if pdf_response.headers.get('content-type') == 'application/pdf':\n",
    "                with open(output_file, 'wb') as file:\n",
    "                    file.write(pdf_response.content)\n",
    "                print(f\"PDF extracted and saved to: {output_file}\")\n",
    "            else:\n",
    "                print(\"The linked file is not a PDF.\")\n",
    "        else:\n",
    "            print(\"No <span> element with class 'standard' found.\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve the link.\")\n",
    "\n",
    "# Example usage\n",
    "link = \"https://www.indiacode.nic.in/handle/123456789/19033?view_type=search&sam_handle=123456789/1362\"  # Replace with the specific link to follow\n",
    "output_file = \"extracted_pdf.pdf\"  # Replace with the desired output file path\n",
    "\n",
    "extract_pdf_from_link(link, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ef421ff8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_pages' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_7364\\502730670.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mspan_link\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m                 \u001b[0mspan_link_href\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"https://www.indiacode.nic.in/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mspan_link\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'href'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[0mnum_pages\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m                     \u001b[0moutput_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"{output_folder}pdf_{i+1}.pdf\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m                     \u001b[0mextract_pdf_from_link\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspan_link_href\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'num_pages' is not defined"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "def extract_pdf_from_link(link, output_file):\n",
    "    response = requests.get(link)\n",
    "    \n",
    "    # Check if the response is successful\n",
    "    if response.status_code == 200:\n",
    "        # Check if the response content type is PDF\n",
    "        if response.headers.get('content-type') == 'application/pdf':\n",
    "            with open(output_file, 'wb') as file:\n",
    "                file.write(response.content)\n",
    "            \n",
    "            # Check if the PDF has at least 30 pages\n",
    "            pdf_reader = PdfReader(output_file)\n",
    "            num_pages = len(pdf_reader.pages)\n",
    "            \n",
    "            if num_pages >= 30:\n",
    "                print(f\"PDF extracted and saved to: {output_file}\")\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            print(\"The linked file is not a PDF.\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve the link.\")\n",
    "\n",
    "# Example usage\n",
    "links_file = \"links.txt\"  # Replace with the path to the file containing the links\n",
    "output_folder = \"C:\\\\Users\\\\AdityaKumar\\\\Downloads\\pdf\"  # Replace with the desired output folder path\n",
    "\n",
    "with open(links_file, 'r') as file:\n",
    "    links = file.readlines()\n",
    "\n",
    "if links:\n",
    "    for i, link in enumerate(links):\n",
    "        link = link.strip()\n",
    "        response = requests.get(link)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        span = soup.find('span', class_='standard')\n",
    "        if span:\n",
    "            span_link = span.find('a')\n",
    "            if span_link:\n",
    "                span_link_href = \"https://www.indiacode.nic.in/\" + span_link['href']\n",
    "                if num_pages >= 30:\n",
    "                    output_file = f\"{output_folder}pdf_{i+1}.pdf\"\n",
    "                    extract_pdf_from_link(span_link_href, output_file)\n",
    "                else:\n",
    "                    pass\n",
    "            \n",
    "else:\n",
    "    print(\"No links found in the file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2433d0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF downloaded and saved to: pdf_hry_short_titles_amendment_act%2c_2021_-_cs.pdf\n",
      "PDF downloaded and saved to: pdf_act_no.1_of_2019_.pdf\n",
      "PDF downloaded and saved to: pdf_a1925-35.pdf\n",
      "PDF downloaded and saved to: pdf_self_supporting_act.pdf\n",
      "PDF downloaded and saved to: pdf_the_abu_area_laws_act%2c_1975.pdf\n",
      "PDF downloaded and saved to: pdf_act_no.1_of_2022.pdf\n",
      "PDF downloaded and saved to: pdf_repealing_%28second%29_act%2c_2016_%2815_of_2017%29.pdf\n",
      "PDF downloaded and saved to: pdf_the_maharashtra_%28change_of_short_titles_of_certain_bombay_acts%29_act%2c_2011.pdf\n",
      "PDF downloaded and saved to: pdf_AA1894___09.pdf\n",
      "PDF downloaded and saved to: pdf_A1967-13.pdf\n",
      "PDF downloaded and saved to: pdf_the_rajasthan_laws_repealing_act%2c_1997.pdf\n",
      "PDF downloaded and saved to: pdf_%2824_of_2012%29the_maharashtra_%28change_of_short_titles_of_certain_bombay_acts%29_act%2c_2011..pdf\n",
      "PDF downloaded and saved to: pdf_a2016____23.pdf\n",
      "PDF downloaded and saved to: pdf_raj._prohibition_act_1981.pdf\n",
      "PDF downloaded and saved to: pdf_the_special_marriage_act_1954_extension_to_nagaland_act_2002.pdf\n",
      "PDF downloaded and saved to: pdf_act_no._1_of_2018.pdf\n",
      "PDF downloaded and saved to: pdf_act_no.5_of_2019.pdf\n",
      "PDF downloaded and saved to: pdf_image_025.pdf\n",
      "PDF downloaded and saved to: pdf_A2018-02.pdf\n",
      "PDF downloaded and saved to: pdf_the_assam_college_education_%28provincialisation%29_act%2c_repealing_act%2c_1998._0.pdf\n",
      "PDF downloaded and saved to: pdf_act_no_vii_of_1961.pdf\n",
      "PDF downloaded and saved to: pdf_the_meghalaya_legislative_assembly_%28fixation_of_quorum%29_act%2c_act_no.7_of_1989.pdf\n",
      "PDF downloaded and saved to: pdf_lokayukta-act-english.pdf\n",
      "PDF downloaded and saved to: pdf_189108.pdf\n",
      "PDF downloaded and saved to: pdf_Athe_meghalaya_benami.pdf\n",
      "PDF downloaded and saved to: pdf_act_no._14.pdf\n",
      "PDF downloaded and saved to: pdf_he_meghalaya_state.pdf\n",
      "PDF downloaded and saved to: pdf_registration_%28amendment_and_validation_of_transfer_of_property%29_act%2c_1955.pdf\n",
      "PDF downloaded and saved to: pdf_ACT%20No.11%20of%202018.pdf\n",
      "PDF downloaded and saved to: pdf_ACT%20NO%2008-2016.pdf\n",
      "PDF downloaded and saved to: pdf_ACT%20No.12%20of%202018.pdf\n",
      "PDF downloaded and saved to: pdf_ACT%20NO%2002-2015.pdf\n",
      "PDF downloaded and saved to: pdf_ACT%20NO%2003-2015.pdf\n",
      "PDF downloaded and saved to: pdf_ACT%20NO%2016-2015.pdf\n",
      "PDF downloaded and saved to: pdf_1542092200950_ACT%20NO%2002-2015.pdf\n",
      "PDF downloaded and saved to: pdf_AP%20Excise%20ACt.pdf\n",
      "PDF downloaded and saved to: pdf_ACT%20NO%2008-2015.pdf\n",
      "PDF downloaded and saved to: pdf_the_rajasthan_state_cattle_fairs_act%2c_1963.pdf\n",
      "PDF downloaded and saved to: pdf_repealingact2004.pdf\n",
      "PDF downloaded and saved to: pdf_A1974-54.pdf\n",
      "PDF downloaded and saved to: pdf_a2019____31.pdf\n",
      "PDF downloaded and saved to: pdf_pb_state_commission_sc_act_2004_amendment_act_2006.pdf\n",
      "PDF downloaded and saved to: pdf_ACT%20NO%2010-2016.pdf\n",
      "PDF downloaded and saved to: pdf_ACT%20NO%2010-2016.pdf\n",
      "PDF downloaded and saved to: pdf_a192524.pdf\n",
      "PDF downloaded and saved to: pdf_36of2011%28E%29.pdf\n",
      "PDF downloaded and saved to: pdf_act_7_of_2017.pdf\n",
      "PDF downloaded and saved to: pdf_52_of_2020_%28e%29.pdf\n",
      "PDF downloaded and saved to: pdf_a1899-2 .pdf\n",
      "PDF downloaded and saved to: pdf_a1899-2 .pdf\n",
      "PDF downloaded and saved to: pdf_a1899-2 .pdf\n",
      "PDF downloaded and saved to: pdf_A1869-04.pdf\n",
      "PDF downloaded and saved to: pdf_A1988-59.pdf\n",
      "PDF downloaded and saved to: pdf_a1899-2 .pdf\n",
      "PDF downloaded and saved to: pdf_a1899-2 .pdf\n",
      "PDF downloaded and saved to: pdf_A1948____08.pdf\n",
      "PDF downloaded and saved to: pdf_A1890-1.pdf\n",
      "PDF downloaded and saved to: pdf_AApolice1861___05.pdf\n",
      "PDF downloaded and saved to: pdf_A1948-63.pdf\n",
      "PDF downloaded and saved to: pdf_16_of_2004_%28e%29.pdf\n",
      "PDF downloaded and saved to: pdf_a1962-42.pdf\n",
      "PDF downloaded and saved to: pdf_act_2_of_1962.pdf\n",
      "PDF downloaded and saved to: pdf_a2015___17.pdf\n",
      "PDF downloaded and saved to: pdf_A1882-04.pdf\n",
      "PDF downloaded and saved to: pdf_the_rajasthan_laws_repealing_act%2c_2015.pdf\n",
      "PDF downloaded and saved to: pdf_189710.pdf\n",
      "PDF downloaded and saved to: pdf_189710.pdf\n",
      "PDF downloaded and saved to: pdf_189710.pdf\n",
      "PDF downloaded and saved to: pdf_189710.pdf\n",
      "PDF downloaded and saved to: pdf_A1915-10.pdf\n",
      "PDF downloaded and saved to: pdf_a2021-40.pdf\n",
      "PDF downloaded and saved to: pdf_pb_state_commission_act_2004_amendment_act_2019.pdf\n",
      "PDF downloaded and saved to: pdf_lambardari_act%2c_1972.pdf\n",
      "PDF downloaded and saved to: pdf_1551073129124_lambardari_act%2c_1972.pdf\n",
      "PDF downloaded and saved to: pdf_the_haryana_settlement_of_outstanding_dues_act%2c_2017%2835_of_2017%29-ulb.pdf\n",
      "PDF downloaded and saved to: pdf_punjab_school_education_board_%28amendment%29_act%2c_2018.pdf\n",
      "PDF downloaded and saved to: pdf_A2018-04.pdf\n",
      "PDF downloaded and saved to: pdf_5._the_kerala_essential_articles_control_%28temporary_powers%29_continuance_act%2c_1979.pdf\n",
      "PDF downloaded and saved to: pdf_TRIPURA%20GENERAL%20CLAUSES%20ACT%2c%201966.pdf\n",
      "PDF downloaded and saved to: pdf_urban_immovable_property_tax_%28repeal_and_saving%29_act%2c_2002.pdf\n",
      "PDF downloaded and saved to: pdf_raj._appropriation_acts_%28repeal%29_act%2c_2017.pdf\n",
      "PDF downloaded and saved to: pdf_a2015----19.pdf\n",
      "PDF downloaded and saved to: pdf_the_meghalaya_municipal_%28garo_hills_autonomous_district%29_act%2c1978%28act_7_of_1978%29.pdf\n",
      "PDF downloaded and saved to: pdf_act_27_of_1956.pdf\n",
      "PDF downloaded and saved to: pdf_1556191273430_ex-417.pdf\n",
      "PDF downloaded and saved to: pdf_1556191424861_ex-416.pdf\n",
      "PDF downloaded and saved to: pdf_23._the_kerala_finance_act_1989_sw.pdf\n",
      "PDF downloaded and saved to: pdf_rti_repeal_act%2c_2006.pdf\n",
      "PDF downloaded and saved to: pdf_extra_ordinary_no._09.pdf\n",
      "PDF downloaded and saved to: pdf_189710.pdf\n",
      "PDF downloaded and saved to: pdf_9%20of%202017.pdf\n",
      "PDF downloaded and saved to: pdf_punjabfisheriesact1914_%281%29.pdf\n",
      "PDF downloaded and saved to: pdf_06%20of%202017.pdf\n",
      "PDF downloaded and saved to: pdf_19%20of%202017.pdf\n",
      "PDF downloaded and saved to: pdf_a1908-13.pdf\n",
      "PDF downloaded and saved to: pdf_a1999-15.pdf\n",
      "PDF downloaded and saved to: pdf_a1992-12.pdf\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def download_pdf_from_link(link, output_file):\n",
    "    response = requests.get(link)\n",
    "    \n",
    "    # Check if the response is successful\n",
    "    if response.status_code == 200:\n",
    "        # Check if the response content type is PDF\n",
    "        if response.headers.get('content-type') == 'application/pdf':\n",
    "            # Check if the PDF has at least 30 pages\n",
    "            if len(response.content) >= 30:\n",
    "                with open(output_file, 'wb') as file:\n",
    "                    file.write(response.content)\n",
    "                print(f\"PDF downloaded and saved to: {output_file}\")\n",
    "            else:\n",
    "                print(\"The PDF does not have at least 30 pages.\")\n",
    "        else:\n",
    "            print(\"The linked file is not a PDF.\")\n",
    "    else:\n",
    "        print(\"Failed to retrieve the link.\")\n",
    "\n",
    "# Example usage\n",
    "links_file = \"links.txt\"  # Replace with the path to the file containing the links\n",
    "\n",
    "with open(links_file, 'r') as file:\n",
    "    links = file.readlines()\n",
    "\n",
    "if links:\n",
    "    for link in links:\n",
    "        link = link.strip()\n",
    "        response = requests.get(link)\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        spans = soup.find_all('span', class_='standard')\n",
    "        for span in spans:\n",
    "            span_link = span.find('a')\n",
    "            if span_link:\n",
    "                span_href = \"https://www.indiacode.nic.in/\" + span_link.get('href')\n",
    "                output_file = f\"pdf_{span_href.split('/')[-1]}\"\n",
    "                download_pdf_from_link(span_href, output_file)\n",
    "else:\n",
    "    print(\"No links found in the file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15652e77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
